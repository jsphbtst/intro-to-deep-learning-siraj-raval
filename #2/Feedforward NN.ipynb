{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weight-height.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gender', 'Height', 'Weight'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(df[['Height', 'Weight']].values)\n",
    "y = df['Gender'].replace('Male', 0).replace('Female', 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WILL UPDATE IN THE FUTURE TO USE ADAM INSTEAD\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, X, y, number_of_nodes_in_hidden_layers):\n",
    "        np.random.seed(1)\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.number_of_nodes_in_hidden_layers = number_of_nodes_in_hidden_layers\n",
    "        \n",
    "        self.X_rows = self.X.shape[0]\n",
    "        self.X_cols = self.X.shape[1]\n",
    "        \n",
    "        if self.X_cols >= self.number_of_nodes_in_hidden_layers:\n",
    "            raise Exception('Number of nodes in hidden layers must be greater than the number of features')\n",
    "        \n",
    "        self.y = self.y.reshape((y.shape[0], 1))        \n",
    "        \n",
    "        # INITIALIZING WEIGHTS\n",
    "        self.weight_0 = 2*np.random.random((self.X_cols, self.number_of_nodes_in_hidden_layers)) - 1\n",
    "        self.weight_1 = 2*np.random.random((self.number_of_nodes_in_hidden_layers, self.number_of_nodes_in_hidden_layers)) - 1\n",
    "        self.weight_2 = 2*np.random.random((self.number_of_nodes_in_hidden_layers, self.X_rows)) - 1\n",
    "        self.weight_3 = 2*np.random.random((self.X_rows, 1)) - 1\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        for i in range(epochs):\n",
    "            # # FORWARD PROPAGATION\n",
    "            input_layer = self.X\n",
    "            layer_1 = self.__sigmoid(np.dot(input_layer, self.weight_0))\n",
    "            layer_2 = self.__sigmoid(np.dot(layer_1, self.weight_1))\n",
    "            layer_3 = self.__sigmoid(np.dot(layer_2, self.weight_2))\n",
    "            output_layer = self.__sigmoid(np.dot(layer_3, self.weight_3))\n",
    "            \n",
    "            # # BACKPROPAGATION\n",
    "            output_layer_error = self.y - output_layer\n",
    "            output_layer_gradient = output_layer_error*self.__sigmoid(output_layer, deriv=True)\n",
    "\n",
    "            if (i% int(epochs/5)) == 0:\n",
    "                print \"Error: \" + str(np.mean(np.abs(output_layer_error)))\n",
    "            \n",
    "            layer_3_error = output_layer_gradient.dot(self.weight_3.T)\n",
    "            layer_3_gradient = layer_3_error*self.__sigmoid(layer_3, deriv=True)\n",
    "\n",
    "            layer_2_error = layer_3_gradient.dot(self.weight_2.T)\n",
    "            layer_2_gradient = layer_2_error*self.__sigmoid(layer_2, deriv=True)\n",
    "\n",
    "            layer_1_error = layer_2_gradient.dot(self.weight_1.T)\n",
    "            layer_1_gradient = layer_1_error*self.__sigmoid(layer_1, deriv=True)\n",
    "\n",
    "            self.weight_3 = self.weight_3 + layer_3.T.dot(output_layer_gradient)\n",
    "            self.weight_2 = self.weight_2 + layer_2.T.dot(layer_3_gradient)\n",
    "            self.weight_1 = self.weight_1 + layer_1.T.dot(layer_2_gradient)\n",
    "            self.weight_0 = self.weight_0 + input_layer.T.dot(layer_1_gradient)\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        layer_1 = self.__sigmoid(np.dot(input_data, self.weight_0))\n",
    "        layer_2 = self.__sigmoid(np.dot(layer_1, self.weight_1))\n",
    "        layer_3 = self.__sigmoid(np.dot(layer_2, self.weight_2))\n",
    "        output_layer = self.__sigmoid(np.dot(layer_3, self.weight_3))        \n",
    "\n",
    "        return output_layer\n",
    "    \n",
    "    def __sigmoid(self, x, deriv=False):\n",
    "        if (deriv==True):\n",
    "            return x * (1 - x)\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.499752648801\n",
      "Error: 0.00399067501062\n",
      "Error: 0.00270869413193\n",
      "Error: 0.0021854241604\n",
      "Error: 0.00188331273905\n",
      "[ 0.99809977]\n"
     ]
    }
   ],
   "source": [
    "sample_X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "sample_y = np.array([0,1,1,0])\n",
    "\n",
    "NN = NeuralNetwork(sample_X, sample_y, 5)\n",
    "\n",
    "NN.train(epochs=60000)\n",
    "print NN.predict(np.array([0,1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.510481536073\n",
      "Error: 0.4895\n",
      "Error: 0.4895\n",
      "Error: 0.4895\n",
      "Error: 0.4895\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetwork(X_train, y_train, 7)\n",
    "NN.train(epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = NN.predict(X_test)\n",
    "y_test_class = y_test\n",
    "y_pred_class = (y_pred > 0.45).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49737500000000001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_class, y_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_test_class, y_pred_class)\n",
    "TP = CM[1, 1]\n",
    "TN = CM[0, 0]\n",
    "FP = CM[0, 1]\n",
    "FN = CM[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.497375\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION ACCURACY\n",
    "print (TP + TN) / float(TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.502625\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION ERROR\n",
    "print (FP + FN) / float(TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Sensitivity: How sensitive is the model in predicting positive instances?\n",
    "print TP / float(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Specificity: When it's actually no, how often does it predict no?\n",
    "# True Negative Rate\n",
    "print TN / float(TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# False Positive Rate: When it's actually no, how often does it predict yes?\n",
    "print FP / float(TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JosephBautista/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Precision: When it predicts yes, how often is it correct?\n",
    "print TP / float(TP + FP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
